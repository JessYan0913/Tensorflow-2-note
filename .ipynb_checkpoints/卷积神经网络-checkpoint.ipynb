{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.卷积\n",
    "\n",
    "利用卷积核提取特征，卷积核中的参数与特征像素点相乘后再相加输出为新的特征。\n",
    "\n",
    "### 1.1.Tensorflow描述\n",
    "\n",
    "```py\n",
    "tk.keras.layers.Conv2D(\n",
    "filter=卷积核个数,\n",
    "kernel_size=卷积核尺寸, #正方形写核长整数，或（核高h, 核宽w）\n",
    "strides=滑动步长, #横纵方向相同步长写整数，或（纵向步长h, 横向步长w）默认1\n",
    "padding='same'or'valid', #使用全零填充是'same'，不使用是'valid'(默认)\n",
    "activation='relu'or'sigmoid'or'tanh'or'softmax', #如果有BN层，此处不写\n",
    "input_shape=(高,宽,通道数) #输入特征图的维度，可以省略\n",
    ")\n",
    "```\n",
    "\n",
    "使用示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "\n",
    "model = models.Sequential([\n",
    "    Conv2D(filters=6, kernel_size=5, padding='valid', activation='sigmoid'),\n",
    "    MaxPool2D(2,2),\n",
    "    Conv2D(filters=6, kernel_size=(5,5), padding='valid', activation='sigmoid'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Conv2D(filters=6, kernel_size=(5,5), padding='valid', activation='sigmoid'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.批标准化 (Batch Normalization BN)\n",
    "标准化：使数据符合均值为0，标准差为1的正态分布。\n",
    "\n",
    "批标准化：对一小批（一个batch）的数据，做标准化。\n",
    "\n",
    "批标准化后，第K个卷积核的输出特征图中第i个像素点：\n",
    "$$\n",
    "H_i^{'k} = \\frac{H_i^k - u_{batch}^k}{r_{batch}^k}\n",
    "$$\n",
    "\n",
    "- $H_i^k$：批标准化之前，第K个卷积核，输出特征图中第i个像素点\n",
    "- $u_{batch}^k$：批标准化之前，第K个卷积核，batch张输出特征图中所有像素点的平均值\n",
    "- $r_{batch}^k$：批标准化之前，第K个卷积核，batch张输出特征图中所有像素点的标准差\n",
    "\n",
    "批标准化操作，将原本偏移的特征数据，重新拉回到0均值，使得特征分布在激活函数的线性区域内，使得输入数据的微小变化更明显的体现到激活函数的输出上。BN操作提升了激活函数对输入数据的区分能力。\n",
    "\n",
    "但是简单的批标准化$H_i^{'k} = \\frac{H_i^k - u_{batch}^k}{r_{batch}^k}$，使得输入数据集中在激活函数中心的线性区域中，使激活函数丧失了非线性特性，因此在BN操作时，为每个卷积核引入两个可训练参数：\n",
    "$$\n",
    "X_i^k = v_kH_i^{'k} + b_k\n",
    "$$\n",
    "\n",
    "- $v_k$：缩放因子\n",
    "- $b_k$：偏移因子\n",
    "\n",
    "在反向传播时，$v_k$和$b_k$会和其他带训练参数一同被训练优化，使标准正态分布后的特征数据，通过缩放因子和偏移因子，优化了特征分布的宽度和偏移量。保证了激活函数的非线性能力。\n",
    "\n",
    "### 2.1.BN操作的位置\n",
    "BN层位于卷积层之后，在激活层之前\n",
    "\n",
    "### 2.2.Tensorflow描述\n",
    "\n",
    "```py\n",
    "tf.keras.layers.BatchNormalization()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    Conv2D(filters=6, kernel_size=(5,5), padding='same'), #卷积\n",
    "    BatchNormalization(), #批标准化\n",
    "    Activation('relu'), #激活层\n",
    "    MaxPool2D(pool_size=(2,2), strides=2, padding='same'), #池化层\n",
    "    Dropout(0.2) #dropout层\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.池化\n",
    "\n",
    "池化操作的目的：在保留特征信息的前提下，减少特征的数据量。\n",
    "\n",
    "常见的池化操作有：\n",
    "- 最大池化：即输出操作核中的最大像素值，用于提取特征图片的纹理\n",
    "- 均值池化：即输出操作和中的像素平均值，用于保留背景特征\n",
    "\n",
    "### 3.1.Tensorflow描述\n",
    "\n",
    "```py\n",
    "tf.keras.layers.MaxPool2D(\n",
    "pool_size=池化核尺寸, #正方形写核长整数，或（核高h, 核宽w）\n",
    "strides=池化步长, #步长整数，或（纵向步长h，横向步长w）默认是pool_size\n",
    "padding='valid'or 'same' #使用全零填充'same'，不使用的话'valid'\n",
    ")\n",
    "\n",
    "tf.keras.layers.AveragePooling2D(\n",
    "pool_size=池化核尺寸, #正方形写核长整数，或（核高h, 核宽w）\n",
    "strides=池化步长, #步长整数，或（纵向步长h，横向步长w）默认是pool_size\n",
    "padding='valid'or 'same' #使用全零填充'same'，不使用的话'valid'\n",
    ")\n",
    "```\n",
    "使用示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    Conv2D(filters=6, kernel_size=(5,5), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2, padding='same'),\n",
    "    Dropout(.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.舍弃 (Dropout)\n",
    "\n",
    "在神经网络训练时，将一部分神经元按照一定概率从神经网络中暂时舍弃。当神经网络使用时，被舍弃的神经元恢复链接。\n",
    "\n",
    "### 4.1.Tensorflow描述\n",
    "\n",
    "```py\n",
    "tf.keras.layers.Dropout(舍弃概率)\n",
    "```\n",
    "\n",
    "使用示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    Conv2D(filters=6, kernel_size=(5,5), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2, padding='same'),\n",
    "    Dropout(.2) #每个神经元被舍弃的概率为20%\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.小结\n",
    "\n",
    "卷积神经网络，是借助卷积核提取特征后，将提取的特征输入全连接网络\n",
    "\n",
    "### 5.1.卷积神经网络的主要模块\n",
    "\n",
    "卷积(convolutional) -> 批标准化(BN) -> 激活(Activation) -> 池化(Pooling) -> 全连接\n",
    "\n",
    "提取特征包括：卷积(convolutional)、批标准化(Batch Normalization BN)、激活(Activation)、池化(Pooling)\n",
    "\n",
    "### 5.2.卷积是什么：\n",
    "\n",
    "卷积就是特征提取器，就是C(Convolutional),B(Batch Normalization),A(Activation),P(Pooling),D(Dropout)\n",
    "\n",
    "```py\n",
    "model = models.Sequential([\n",
    "    Conv2D(filters=6, kernel_size=(5,5), padding='same'), # C\n",
    "    BatchNormalization(),                                 # B\n",
    "    Activation('relu'),                                   # A\n",
    "    MaxPool2D(pool_size=(2,2), strides=2, padding='same'),# P \n",
    "    Dropout(.2)                                           # D\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
