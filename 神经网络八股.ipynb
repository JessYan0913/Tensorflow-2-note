{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六步搭建网络\n",
    "\n",
    "- **import** 导入相关模块\n",
    "\n",
    "- **train,test** 划分训练数据集和测试数据集\n",
    "\n",
    "- **model = keras.models.Sequential** 搭建网络结构，相当于走了一边前向传播\n",
    "\n",
    "- **model.compile** 配置训练时的优化器、损失函数、评测指标\n",
    "\n",
    "- **model.fit** 训练网络，配置训练集和测试集的特征、迭代次数、每次喂入的大小\n",
    "\n",
    "- **model.summary** 查看训练后的网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential([网络结构])\n",
    "\n",
    "例如：\n",
    "\n",
    "拉直层：`keras.layers.Flatten()`，不做计算，只将输入特征拉直成一维\n",
    "\n",
    "全连接层：`keras.layers.Dense(神经元个数, activation='激活函数', kernel_regularizer=正则化)`\n",
    "\n",
    "> `activation`使用字符串配置，可选用的有：relu、softmax、sigmoid、tanh\n",
    "\n",
    "> `kernel_regularizer`可选的有：keras.regularizers.l1()、keras.regularizers.l2()\n",
    "\n",
    "卷积层： `keras.layers.Conv2D(filters=卷积核个数, kernel_size=卷积核尺寸, strides=卷积步长, padding='vaild'or'same')`\n",
    "\n",
    "循环神经网络(LSTM)层：`keras.layers.LSTM()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.compile(optimizer=优化器, loss=损失函数, metrics=['准确率'])\n",
    "\n",
    "### optimizer（优化器）\n",
    "\n",
    "`'sgd'`or`keras.optimizer.SGD(lr=学习率, momentum=动量参数)`\n",
    "\n",
    "`'adagrad'`or`keras.optimizer.Adagrad(lr=学习率)`\n",
    "\n",
    "`'adadelta'`or`keras.optimizer.Adadelta(lr=学习率)`\n",
    "\n",
    "`'adam'`or`keras.optimizer.Adam(lr=学习率, beta_1=0.9, beta_2=0.999)`\n",
    "\n",
    "### loss（损失函数）\n",
    "\n",
    "`'mse'`or`keras.losses.MeanSquaredError()`\n",
    "\n",
    "`'sparse_categorical_crossentropy'`or`keras.losses.SparesCategoricalCrossentropy(form_logits=False)`\n",
    "\n",
    "> `form_logits`是否是原始输出，即就是没有经过概率分布的输出，若神经网络输出前需要经过概率分布处理则`form_logits=False`\n",
    "\n",
    "### metrics（评测指标）\n",
    "\n",
    "`accuracy`：y_和y都是数值形式，例如：y_=[1] y= [1]，也就是分类标签用数值表示，输出结果也是数值\n",
    "\n",
    "`categorical_accuracy`：y_和y都是独热码(概率分布)，例如：y_=[1,0,0] y=[0.33, 0.43, 0.32]\n",
    "\n",
    "`sparese_categorical_accuracy`：y_是数值，y是独热码表示，例如：y_=[1] y=[0.256,0.695, 0.048]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.fit(训练集的输入特征, 训练集的标签,  batch_size=每次喂入的大小, epochs=循环多少轮, validation_data=（测试集的输入特征，测试集的标签）, validation_split=从训练集划分出多少比例的测试集, validation_freq=多少次epoch回测一次)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强（增大数据量）\n",
    "\n",
    "```py\n",
    "image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale= 所有数据将要与该数值相乘\n",
    "    rotation_range= 随机旋转角度数范围\n",
    "    width_shift_range= 随机宽度偏移量\n",
    "    height_shift_range= 随机高度偏移量\n",
    "    horizontal_flip= 是否水平反转\n",
    "    zoom_range= 随机缩放范围[1-n, 1+n]\n",
    ")\n",
    "\n",
    "image_gen_train.fit(x_train)\n",
    "```\n",
    "\n",
    "例如：\n",
    "```py \n",
    "image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255., #将图像中的元素全部除以255\n",
    "    rotation_range=45, #随机45度旋转\n",
    "    width_shift_range=.15, #宽度偏移0.15倍\n",
    "    height_shift_range=.15, #高度偏移0.15倍\n",
    "    horizontal_flip=False, #不进行水平翻转\n",
    "    zoom_range=.5 #将图像随机缩放.5倍 \n",
    ")\n",
    "```\n",
    "\n",
    "`image_gen_train.fit(x_train)`需要输入的数据是4维数据即(个数，宽度， 高度， 通道数)\n",
    "\n",
    "```py \n",
    "#将x_train 从(60000, 28, 28)变形为(60000, 28, 28, 1)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 断点续训\n",
    "\n",
    "### 读取模型\n",
    "```py \n",
    "model.load_weights(模型保存路径)\n",
    "```\n",
    "例如：\n",
    "```py \n",
    "checkpoint_save_path = './checkpoint/mnist.ckpt'\n",
    "# 因为模型保存为ckpt文件时，会同步生成索引表.index,所以通过判断是否又索引表就可以判断是否有保存好的模型\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('------load the model-------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "```\n",
    "\n",
    "### 保存模型\n",
    "```py\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=模型保存路径, #文件存储路径\n",
    "    save_weights_only=True/False, #是否只保留模型参数\n",
    "    save_best_only=True/False, #是否只保留最优结果\n",
    ")\n",
    "\n",
    "#执行训练过程时\n",
    "history = model.fit(callback=[cp_callback])\n",
    "```\n",
    "\n",
    "例如：\n",
    "```py \n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_save_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1, callbacks=[cp_callback])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数提取\n",
    "\n",
    "### 提取可选参数\n",
    "`model.trainable_variables`返回模型中可训练的参数\n",
    "\n",
    "### 设置print输出格式\n",
    "\n",
    "`np.set_printoptions(threshold=超过多少省略显示)`\n",
    "\n",
    "例如:\n",
    "\n",
    "np.inf表示无限大\n",
    "`np.set_printoptions(threshold=np.inf)`\n",
    "\n",
    "### 将训练参数存入文本\n",
    "\n",
    "```py \n",
    "print(model.trainable_variables)\n",
    "file = open('weights.txt', 'w')\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化acc曲线和loss曲线\n",
    "\n",
    "```py \n",
    "history = model.fit(训练数据集，训练标签集，batch_size=，epochs=，\n",
    "    validation_split=用作测试的数据比例，\n",
    "    validation_data=测试集，#只能和validation_split存在一个\n",
    "    validation_freq=测试间隔 #即训练多少轮测试一次\n",
    ")\n",
    "```\n",
    "\n",
    "history:\n",
    "\n",
    "- 训练集loss: loss\n",
    "- 测试集loss: val_loss\n",
    "- 训练集准确率: sparse_categorical_accuracy\n",
    "- 测试集准确率: val_sparse_categorical_accuracy\n",
    "\n",
    "代码：\n",
    "\n",
    "```py \n",
    "acc = history.history['sparse_categorical_accuracy']\n",
    "val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Train and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}