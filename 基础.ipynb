{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建张量\n",
    "\n",
    "```python\n",
    "tf.constant(张量内容, dtype=数据类型)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 5], shape=(2,), dtype=int64)\n",
      "(2,)\n",
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([1, 5], dtype=tf.int64)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shape`中有几个逗号隔开的数字，就是有几维\n",
    "\n",
    "将`numpy`类型的数据转换为`tensor`类型\n",
    "\n",
    "```python\n",
    "tf.convert_to_tensor(数据名， dtype=数据类型)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(1,10)\n",
    "d = tf.convert_to_tensor(a, dtype=tf.int32)\n",
    "print(a)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全零的`tensor`张量\n",
    "\n",
    "```python\n",
    "tf.zeros(维度)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.zeros(shape=(2,3))\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全1的`tensor`张量\n",
    "```python\n",
    "tf.ones(维度)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tf.ones(shape=(2,3))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全指定数据张量\n",
    "```python\n",
    "tf.fill(维度, 指定的值)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[10, 10, 10],\n",
       "       [10, 10, 10]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tf.fill([2, 3], 10)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成正态分布的随机数，默认值为0，标准差为1\n",
    "```python\n",
    "tf.random.normal(维度, mean=均值, stddev=标准差)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.82506275, 2.2988374 , 1.1321012 ],\n",
       "       [1.0544784 , 0.3067587 , 1.4552938 ]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = tf.random.normal(shape=[2,3], mean=1, stddev=.5)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成截断式的正态分布的随机数\n",
    "```python\n",
    "tf.random.truncated_normal(维度, mean=均值, stddev=标准差)\n",
    "```\n",
    "如果生成的数值在(均值-2*标准差，均值+2*标准差)之外的话会重新生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1.3488824 , 1.3713413 , 0.8954021 ],\n",
       "       [0.98434776, 0.8150234 , 1.4957652 ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = tf.random.truncated_normal(shape=(2,3), mean=1, stddev=.5)\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成均匀分布的随机数\n",
    "```python\n",
    "tf.random.uniform(维度, maxval=最大值, minval=最小值)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[91.690254, 53.101273, 72.16043 ],\n",
       "       [50.748016, 84.61701 , 78.71806 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = tf.random.uniform(shape=(2,3), maxval=100, minval=50)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常量函数\n",
    "\n",
    "强制`tensor`**转换数据类型**。\n",
    "```python\n",
    "tf.cast(张量名, dtype=数据类型)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 5.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([1 5], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.constant([1,5], dtype=tf.float32)\n",
    "x2 = tf.cast(x1, dtype=tf.int64)\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算`tensor`中的**最小值**和**最大值**。\n",
    "```python\n",
    "tf.reduce_max(张量名)\n",
    "\n",
    "tf.reduce_min(张量名)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1中的最大值是5.0，最小值是1.0\n"
     ]
    }
   ],
   "source": [
    "x1_max = tf.reduce_max(x1)\n",
    "x1_min = tf.reduce_min(x1)\n",
    "print('x1中的最大值是{}，最小值是{}'.format(x1_max, x1_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算`tensor`中的**均值**。\n",
    "```python\n",
    "tf.reduce_mean(张量名)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1的均值是3.0\n"
     ]
    }
   ],
   "source": [
    "x1_mean = tf.reduce_mean(x1)\n",
    "print('x1的均值是{}'.format(x1_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算`tensor`的**和**。\n",
    "```python\n",
    "tf.reduce_sum(张量名)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1的和是6.0\n"
     ]
    }
   ],
   "source": [
    "x1_sum = tf.reduce_sum(x1)\n",
    "print('x1的和是{}'.format(x1_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`axis`属性控制**计算的方向**，在二维张量中`axis=0`是指对列操作，`axis=1`是指对行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 5, 7], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1, 2, 3], [3, 4, 5], [5, 6, 7]])\n",
    "x_max_1 = tf.reduce_max(x, axis=1)\n",
    "x_max_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 6, 7], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_max_0 = tf.reduce_max(x, axis=0)\n",
    "x_max_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 6, 12, 18], dtype=int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sum_1 = tf.reduce_sum(x, axis=1)\n",
    "x_sum_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 9, 12, 15], dtype=int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sum_0 = tf.reduce_sum(x, axis=0)\n",
    "x_sum_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标记可训练的变量\n",
    "\n",
    "`tf.Variabe()`将变量标记为`可训练`的变量，被标记的变量在反向传播的过程中将被记录梯度信息。在神经网络中标记待训练的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化参数W\n",
    "w = tf.Variable(tf.random.normal([2,4], mean=0, stddev=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用的向量计算\n",
    "\n",
    "`tf.add()`张量的和\n",
    "\n",
    "`tf.subtract()`张量的差\n",
    "\n",
    "`tf.multiply()`张量的积\n",
    "\n",
    "`tf.divide()`张量的除\n",
    "\n",
    "`tf.square()`张量的平方\n",
    "\n",
    "`tf.pow()`张量的次方\n",
    "\n",
    "`tf.sqrt()`张量的开放\n",
    "\n",
    "`tf.matmul()`张量的矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([6, 8], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1,2])\n",
    "w = tf.constant([5,6])\n",
    "\n",
    "tf.add(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([-4, -4], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.subtract(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 5, 12], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.2       , 0.33333333])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.divide(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([25, 36], dtype=int32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.pow(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[6., 6., 6.],\n",
       "       [6., 6., 6.],\n",
       "       [6., 6., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([3,2])\n",
    "b = tf.fill([2,3], 3.)\n",
    "#注意数据类型要一致\n",
    "tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征和标签配对\n",
    "\n",
    "`tf.data.Dataset.from_tensor_slices`可以将输入的特征和对应的标签进行绑定，构建数据集。\n",
    "\n",
    "```python\n",
    "data = tf.data.Dataset.from_tensor_slices((输入特征，标签))\n",
    "```\n",
    "\n",
    "支持`numpy`格式的数据输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((2,), ()), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "features = tf.constant([[1,2],[2,3]])\n",
    "labels = tf.constant([1,0])\n",
    "data = tf.data.Dataset.from_tensor_slices((features,labels))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "for element in data:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对指定参数求导\n",
    "\n",
    "`tf.GradientTape`可以实现函数中的某个参数的求导运算。\n",
    "\n",
    "```python\n",
    "with tf.GradientTape() as tape:\n",
    "    ....\n",
    "tape.gradient(函数，对谁求导)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    w = tf.Variable(tf.constant(3.))\n",
    "    loss = tf.pow(w, 2)\n",
    "grad = tape.gradient(loss, w)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "loss = w^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial_{w^2}}{\\partial_{w}} = 2w = 2 * 3.0 = 6.0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 枚举\n",
    "\n",
    "`enumerate`是python内建函数，可以遍历每个元素（例如列表、元组和字符串），组合为：**索引 元素**，常在for 中使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> one\n",
      "1 -> two\n",
      "2 -> three\n"
     ]
    }
   ],
   "source": [
    "seq = ['one', 'two', 'three']\n",
    "for i, element in enumerate(seq):\n",
    "    print('{} -> {}'.format(i, element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独热编码\n",
    "`tf.one_hot`是tf总自带的**独热编码**，在分类问题中，常用独热编码做标签，标记类别：1表示是，0表示非\n",
    "\n",
    "```python\n",
    "tf.one_hot(待转换数据, depth=几分类)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = 4\n",
    "#表示输入的元素最小为0，最大为4\n",
    "labels = tf.constant([1, 0, 3, 2])\n",
    "tf.one_hot(labels, depth=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数 softmax\n",
    "\n",
    "假如分类问题输出的是`[1.01, 2.02, -0.33, 3.33]`这样的输出不符合概率分布，只有符合概率分布的输出才可以于**独热码**比较\n",
    "\n",
    "$$\n",
    "\\frac{e^{y_i}}{\\sum_{j=0}^{n}e^{y_i}}\n",
    "$$\n",
    "\n",
    "用该公式计算可知：\n",
    "$$\n",
    "\\frac{e^{y_0}}{e^{y_0}+e^{y_1}+e^{y_2}+e^{y_3}} = \\frac{e^1.01}{e^{1.01}+e^{2.02}+e^{-0.33}+e^{3.33}} \\approx 0.07\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{e^{y_1}}{e^{y_0}+e^{y_1}+e^{y_2}+e^{y_3}} = \\frac{e^2.02}{e^{1.01}+e^{2.02}+e^{-0.33}+e^{3.33}} \\approx 0.194\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{e^{y_2}}{e^{y_0}+e^{y_1}+e^{y_2}+e^{y_3}} = \\frac{e^{-0.33}}{e^{1.01}+e^{2.02}+e^{-0.33}+e^{3.33}} \\approx 0.018\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{e^{y_3}}{e^{y_0}+e^{y_1}+e^{y_2}+e^{y_3}} = \\frac{e^3.33}{e^{1.01}+e^{2.02}+e^{-0.33}+e^{3.33}} \\approx 0.717\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当n分类的n个输出$(y_0, y_1, ...y_{n-1})$通过`tf.softmax()`函数后会更符合概率分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过softmax后的y = [0.07050634 0.19358228 0.01846178 0.71744955]\n"
     ]
    }
   ],
   "source": [
    "y = tf.constant([1.01, 2.02, -0.33, 3.33])\n",
    "y_pro = tf.nn.softmax(y)\n",
    "print('经过softmax后的y = {}'.format(y_pro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(y_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数自更新 assign_sub\n",
    "\n",
    "负值操作，更新参数的值并返回新的值。\n",
    "\n",
    "调用`assign_sub`前，先用`tf.Variable`定义变量`w`为可训练（可自更新）\n",
    "\n",
    "```python\n",
    "w.assign_sub(n) # w-=n\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(4)\n",
    "w.assign_sub(1)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 返回张量的最大值索引\n",
    "\n",
    "`tf.argmax()`返回张量沿指定维度最大值的索引号\n",
    "\n",
    "```python\n",
    "tf.argmax(张量名称, axis=操作轴)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 3  8  5]\n",
      " [ 9  6  7]\n",
      " [ 9  6 11]]\n",
      "tf.Tensor([2 1 3], shape=(3,), dtype=int64)\n",
      "tf.Tensor([2 1 0 2], shape=(4,), dtype=int64)\n",
      "tf.Tensor([0 0 0], shape=(3,), dtype=int64)\n",
      "tf.Tensor([0 0 1 1], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = np.array([[1, 2, 3], [3, 8, 5], [9, 6, 7], [9, 6, 11]])\n",
    "print(test)\n",
    "print(tf.argmax(test, axis=0))\n",
    "print(tf.argmax(test, axis=1))\n",
    "print(tf.argmin(test, axis=0))\n",
    "print(tf.argmin(test, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
